/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

String flinkVersion = '1.14.0'
String flinkMajorVersion = '1.14'
String scalaVersion = System.getProperty("scalaVersion") != null ? System.getProperty("scalaVersion") : System.getProperty("defaultScalaVersion")

project(":iceberg-flink:iceberg-flink-${flinkMajorVersion}") {

  dependencies {
    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')
    api project(':iceberg-api')
    implementation project(':iceberg-common')
    implementation project(':iceberg-core')
    api project(':iceberg-data')
    implementation project(':iceberg-orc')
    implementation project(':iceberg-parquet')
    implementation project(':iceberg-hive-metastore')

    // for dropwizard histogram metrics implementation
    compileOnly "org.apache.flink:flink-metrics-dropwizard:${flinkVersion}"
    compileOnly "org.apache.flink:flink-streaming-java_${scalaVersion}:${flinkVersion}"
    compileOnly "org.apache.flink:flink-streaming-java_${scalaVersion}:${flinkVersion}:tests"
    compileOnly "org.apache.flink:flink-table-api-java-bridge_${scalaVersion}:${flinkVersion}"
    compileOnly "org.apache.flink:flink-table-planner_${scalaVersion}:${flinkVersion}"
    compileOnly "org.apache.hadoop:hadoop-hdfs"
    compileOnly "org.apache.hadoop:hadoop-common"
    compileOnly("org.apache.hadoop:hadoop-minicluster") {
      exclude group: 'org.apache.avro', module: 'avro'
    }

    implementation("org.apache.parquet:parquet-avro") {
      exclude group: 'org.apache.avro', module: 'avro'
      // already shaded by Parquet
      exclude group: 'it.unimi.dsi'
      exclude group: 'org.codehaus.jackson'
    }

    compileOnly "org.apache.avro:avro"

    implementation("org.apache.orc:orc-core::nohive") {
      exclude group: 'org.apache.hadoop'
      exclude group: 'commons-lang'
      // These artifacts are shaded and included in the orc-core fat jar
      exclude group: 'com.google.protobuf', module: 'protobuf-java'
      exclude group: 'org.apache.hive', module: 'hive-storage-api'
    }

    testImplementation "org.apache.flink:flink-connector-test-utils:${flinkVersion}"
    testImplementation "org.apache.flink:flink-core:${flinkVersion}"
    testImplementation "org.apache.flink:flink-runtime:${flinkVersion}"
    testImplementation ("org.apache.flink:flink-test-utils-junit:${flinkVersion}") {
      exclude group: 'junit'
    }
    testImplementation("org.apache.flink:flink-test-utils_${scalaVersion}:${flinkVersion}") {
      exclude group: "org.apache.curator", module: 'curator-test'
      exclude group: 'junit'
    }

    testImplementation project(path: ':iceberg-hive-metastore', configuration: 'testArtifacts')
    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')
    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')
    testImplementation project(path: ':iceberg-data', configuration: 'testArtifacts')

    // By default, hive-exec is a fat/uber jar and it exports a guava library
    // that's really old. We use the core classifier to be able to override our guava
    // version. Luckily, hive-exec seems to work okay so far with this version of guava
    // See: https://github.com/apache/hive/blob/master/ql/pom.xml#L911 for more context.
    testImplementation("org.apache.hive:hive-exec::core") {
      exclude group: 'org.apache.avro', module: 'avro'
      exclude group: 'org.slf4j', module: 'slf4j-log4j12'
      exclude group: 'org.pentaho' // missing dependency
      exclude group: 'org.apache.hive', module: 'hive-llap-tez'
      exclude group: 'org.apache.logging.log4j'
      exclude group: 'com.google.protobuf', module: 'protobuf-java'
      exclude group: 'org.apache.calcite'
      exclude group: 'org.apache.calcite.avatica'
      exclude group: 'com.google.code.findbugs', module: 'jsr305'
    }

    testImplementation("org.apache.hive:hive-metastore") {
      exclude group: 'org.apache.avro', module: 'avro'
      exclude group: 'org.slf4j', module: 'slf4j-log4j12'
      exclude group: 'org.pentaho' // missing dependency
      exclude group: 'org.apache.hbase'
      exclude group: 'org.apache.logging.log4j'
      exclude group: 'co.cask.tephra'
      exclude group: 'com.google.code.findbugs', module: 'jsr305'
      exclude group: 'org.eclipse.jetty.aggregate', module: 'jetty-all'
      exclude group: 'org.eclipse.jetty.orbit', module: 'javax.servlet'
      exclude group: 'org.apache.parquet', module: 'parquet-hadoop-bundle'
      exclude group: 'com.tdunning', module: 'json'
      exclude group: 'javax.transaction', module: 'transaction-api'
      exclude group: 'com.zaxxer', module: 'HikariCP'
    }
  }
}

project(":iceberg-flink:iceberg-flink-runtime-${flinkMajorVersion}") {
  apply plugin: 'com.github.johnrengelman.shadow'

  tasks.jar.dependsOn tasks.shadowJar

  sourceSets {
    integration {
      java.srcDir "$projectDir/src/integration/java"
      resources.srcDir "$projectDir/src/integration/resources"
    }
  }

  configurations {
    implementation {
      // included in Flink
      exclude group: 'org.slf4j'
      exclude group: 'org.apache.commons'
      exclude group: 'commons-pool'
      exclude group: 'commons-codec'
      exclude group: 'org.xerial.snappy'
      exclude group: 'javax.xml.bind'
      exclude group: 'javax.annotation'
    }
  }

  dependencies {
    implementation(project(":iceberg-flink:iceberg-flink-${flinkMajorVersion}")) {
      exclude group: 'org.apache.flink'
    }
    implementation project(':iceberg-aws')
    implementation(project(':iceberg-aliyun')) {
      exclude group: 'edu.umd.cs.findbugs', module: 'findbugs'
      exclude group: 'org.apache.httpcomponents', module: 'httpclient'
      exclude group: 'commons-logging', module: 'commons-logging'
    }
    implementation(project(':iceberg-nessie')) {
      exclude group: 'com.google.code.findbugs', module: 'jsr305'
    }

    // for dropwizard histogram metrics implementation
    implementation "org.apache.flink:flink-metrics-dropwizard:${flinkVersion}"

    // for integration testing with the flink-runtime-jar
    // all of those dependencies are required because the integration test extends FlinkTestBase
    integrationCompileOnly project(':iceberg-api')
    integrationImplementation 'org.junit.vintage:junit-vintage-engine'
    integrationImplementation 'org.assertj:assertj-core'
    integrationImplementation project(path: ":iceberg-flink:iceberg-flink-${flinkMajorVersion}", configuration: "testArtifacts")
    integrationImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')
    integrationImplementation project(path: ':iceberg-hive-metastore', configuration: 'testArtifacts')
    integrationImplementation("org.apache.flink:flink-test-utils_${scalaVersion}:${flinkVersion}") {
      exclude group: "org.apache.curator", module: 'curator-test'
      exclude group: 'junit'
    }

    integrationImplementation "org.apache.flink:flink-table-api-java-bridge_${scalaVersion}:${flinkVersion}"
    integrationImplementation "org.apache.flink:flink-table-planner_${scalaVersion}:${flinkVersion}"

    integrationImplementation "org.apache.hadoop:hadoop-common"
    integrationImplementation "org.apache.hadoop:hadoop-hdfs"
    integrationImplementation("org.apache.hadoop:hadoop-minicluster") {
      exclude group: 'org.apache.avro', module: 'avro'
    }

    integrationImplementation("org.apache.hive:hive-metastore") {
      exclude group: 'org.apache.avro', module: 'avro'
      exclude group: 'org.slf4j', module: 'slf4j-log4j12'
      exclude group: 'org.pentaho' // missing dependency
      exclude group: 'org.apache.hbase'
      exclude group: 'org.apache.logging.log4j'
      exclude group: 'co.cask.tephra'
      exclude group: 'com.google.code.findbugs', module: 'jsr305'
      exclude group: 'org.eclipse.jetty.aggregate', module: 'jetty-all'
      exclude group: 'org.eclipse.jetty.orbit', module: 'javax.servlet'
      exclude group: 'org.apache.parquet', module: 'parquet-hadoop-bundle'
      exclude group: 'com.tdunning', module: 'json'
      exclude group: 'javax.transaction', module: 'transaction-api'
      exclude group: 'com.zaxxer', module: 'HikariCP'
    }

    integrationImplementation("org.apache.hive:hive-exec::core") {
      exclude group: 'org.apache.avro', module: 'avro'
      exclude group: 'org.slf4j', module: 'slf4j-log4j12'
      exclude group: 'org.pentaho' // missing dependency
      exclude group: 'org.apache.hive', module: 'hive-llap-tez'
      exclude group: 'org.apache.logging.log4j'
      exclude group: 'com.google.protobuf', module: 'protobuf-java'
      exclude group: 'org.apache.calcite'
      exclude group: 'org.apache.calcite.avatica'
      exclude group: 'com.google.code.findbugs', module: 'jsr305'
    }
  }

  shadowJar {
    configurations = [project.configurations.runtimeClasspath]

    zip64 true

    // include the LICENSE and NOTICE files for the shaded Jar
    from(projectDir) {
      include 'LICENSE'
      include 'NOTICE'
    }

    // Relocate dependencies to avoid conflicts
    relocate 'org.apache.avro', 'org.apache.iceberg.shaded.org.apache.avro'
    relocate 'org.apache.parquet', 'org.apache.iceberg.shaded.org.apache.parquet'
    relocate 'com.google', 'org.apache.iceberg.shaded.com.google'
    relocate 'com.fasterxml', 'org.apache.iceberg.shaded.com.fasterxml'
    relocate 'com.github.benmanes', 'org.apache.iceberg.shaded.com.github.benmanes'
    relocate 'org.checkerframework', 'org.apache.iceberg.shaded.org.checkerframework'
    relocate 'shaded.parquet', 'org.apache.iceberg.shaded.org.apache.parquet.shaded'
    relocate 'org.apache.orc', 'org.apache.iceberg.shaded.org.apache.orc'
    relocate 'io.airlift', 'org.apache.iceberg.shaded.io.airlift'
    relocate 'org.threeten.extra', 'org.apache.iceberg.shaded.org.threeten.extra'
    relocate 'org.apache.httpcomponents.client5', 'org.apache.iceberg.shaded.org.apache.httpcomponents.client5'

    classifier null
  }

  task integrationTest(type: Test) {
    description = "Test Flink Runtime Jar against Flink ${flinkMajorVersion}"
    group = "verification"
    testClassesDirs = sourceSets.integration.output.classesDirs
    classpath = sourceSets.integration.runtimeClasspath + files(shadowJar.archiveFile.get().asFile.path)
    inputs.file(shadowJar.archiveFile.get().asFile.path)
  }
  integrationTest.dependsOn shadowJar
  check.dependsOn integrationTest

  jar {
    enabled = false
  }
}
