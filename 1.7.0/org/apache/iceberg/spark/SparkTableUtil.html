<!DOCTYPE HTML>
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc -->
<title>SparkTableUtil</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../jquery/jquery-ui.min.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../jquery-ui.overrides.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
<script type="text/javascript" src="../../../../jquery/jszip/dist/jszip.min.js"></script>
<script type="text/javascript" src="../../../../jquery/jszip-utils/dist/jszip-utils.min.js"></script>
<!--[if IE]>
<script type="text/javascript" src="../../../../jquery/jszip-utils/dist/jszip-utils-ie.min.js"></script>
<![endif]-->
<script type="text/javascript" src="../../../../jquery/jquery-3.7.1.min.js"></script>
<script type="text/javascript" src="../../../../jquery/jquery-ui.min.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="SparkTableUtil";
        }
    }
    catch(err) {
    }
//-->
var data = {"i0":9,"i1":9,"i2":9,"i3":9,"i4":9,"i5":9,"i6":9,"i7":9,"i8":9,"i9":9,"i10":9,"i11":9,"i12":9,"i13":9,"i14":9,"i15":9,"i16":9,"i17":9,"i18":9,"i19":9,"i20":9,"i21":9,"i22":9};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
var pathtoroot = "../../../../";
var useModuleDirectories = true;
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<header role="banner">
<nav role="navigation">
<div class="fixedNav">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a id="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a id="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses.html">All&nbsp;Classes</a></li>
</ul>
<ul class="navListSearch">
<li><label for="search">SEARCH:</label>
<input type="text" id="search" value="search" disabled="disabled">
<input type="reset" id="reset" value="reset" disabled="disabled">
</li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a id="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
</div>
<div class="navPadding">&nbsp;</div>
<script type="text/javascript"><!--
$('.navPadding').css('padding-top', $('.fixedNav').css("height"));
//-->
</script>
</nav>
</header>
<!-- ======== START OF CLASS DATA ======== -->
<main role="main">
<div class="header">
<div class="subTitle"><span class="packageLabelInType">Package</span>&nbsp;<a href="package-summary.html">org.apache.iceberg.spark</a></div>
<h2 title="Class SparkTableUtil" class="title">Class SparkTableUtil</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.apache.iceberg.spark.SparkTableUtil</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<pre>public class <span class="typeNameLabel">SparkTableUtil</span>
extends java.lang.Object</pre>
<div class="block">Java version of the original SparkTableUtil.scala
 https://github.com/apache/iceberg/blob/apache-iceberg-0.8.0-incubating/spark/src/main/scala/org/apache/iceberg/spark/SparkTableUtil.scala</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<section>
<ul class="blockList">
<li class="blockList"><a id="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="memberSummary">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colSecond" scope="col">Class</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a></span></code></th>
<td class="colLast">
<div class="block">Class representing a table partition.</div>
</td>
</tr>
</table>
</li>
</ul>
</section>
<!-- ========== METHOD SUMMARY =========== -->
<section>
<ul class="blockList">
<li class="blockList"><a id="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colSecond" scope="col">Method</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>static java.lang.String</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#determineWriteBranch(org.apache.spark.sql.SparkSession,java.lang.String)">determineWriteBranch</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                    java.lang.String&nbsp;branch)</code></th>
<td class="colLast">
<div class="block">Determine the write branch.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>static java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#filterPartitions(java.util.List,java.util.Map)">filterPartitions</a></span>&#8203;(java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter)</code></th>
<td class="colLast">&nbsp;</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>static java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#getPartitions(org.apache.spark.sql.SparkSession,java.lang.String)">getPartitions</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
             java.lang.String&nbsp;table)</code></th>
<td class="colLast">
<div class="block">Returns all partitions in the table.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>static java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#getPartitions(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,java.util.Map)">getPartitions</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
             org.apache.spark.sql.catalyst.TableIdentifier&nbsp;tableIdent,
             java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter)</code></th>
<td class="colLast">
<div class="block">Returns all partitions in the table.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>static java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#getPartitionsByFilter(org.apache.spark.sql.SparkSession,java.lang.String,java.lang.String)">getPartitionsByFilter</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                     java.lang.String&nbsp;table,
                     java.lang.String&nbsp;predicate)</code></th>
<td class="colLast">
<div class="block">Returns partitions that match the specified 'predicate'.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>static java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#getPartitionsByFilter(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.expressions.Expression)">getPartitionsByFilter</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                     org.apache.spark.sql.catalyst.TableIdentifier&nbsp;tableIdent,
                     org.apache.spark.sql.catalyst.expressions.Expression&nbsp;predicateExpr)</code></th>
<td class="colLast">
<div class="block">Returns partitions that match the specified 'predicate'.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkPartitions(org.apache.spark.sql.SparkSession,java.util.List,org.apache.iceberg.Table,org.apache.iceberg.PartitionSpec,java.lang.String)">importSparkPartitions</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                     java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                     <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                     <a href="../PartitionSpec.html" title="class in org.apache.iceberg">PartitionSpec</a>&nbsp;spec,
                     java.lang.String&nbsp;stagingDir)</code></th>
<td class="colLast">
<div class="block">Import files from given partitions to an Iceberg table.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkPartitions(org.apache.spark.sql.SparkSession,java.util.List,org.apache.iceberg.Table,org.apache.iceberg.PartitionSpec,java.lang.String,boolean)">importSparkPartitions</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                     java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                     <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                     <a href="../PartitionSpec.html" title="class in org.apache.iceberg">PartitionSpec</a>&nbsp;spec,
                     java.lang.String&nbsp;stagingDir,
                     boolean&nbsp;checkDuplicateFiles)</code></th>
<td class="colLast">
<div class="block">Import files from given partitions to an Iceberg table.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkPartitions(org.apache.spark.sql.SparkSession,java.util.List,org.apache.iceberg.Table,org.apache.iceberg.PartitionSpec,java.lang.String,boolean,int)">importSparkPartitions</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                     java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                     <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                     <a href="../PartitionSpec.html" title="class in org.apache.iceberg">PartitionSpec</a>&nbsp;spec,
                     java.lang.String&nbsp;stagingDir,
                     boolean&nbsp;checkDuplicateFiles,
                     int&nbsp;parallelism)</code></th>
<td class="colLast">
<div class="block">Import files from given partitions to an Iceberg table.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkPartitions(org.apache.spark.sql.SparkSession,java.util.List,org.apache.iceberg.Table,org.apache.iceberg.PartitionSpec,java.lang.String,boolean,java.util.concurrent.ExecutorService)">importSparkPartitions</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                     java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                     <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                     <a href="../PartitionSpec.html" title="class in org.apache.iceberg">PartitionSpec</a>&nbsp;spec,
                     java.lang.String&nbsp;stagingDir,
                     boolean&nbsp;checkDuplicateFiles,
                     java.util.concurrent.ExecutorService&nbsp;service)</code></th>
<td class="colLast">
<div class="block">Import files from given partitions to an Iceberg table.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String)">importSparkTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                java.lang.String&nbsp;stagingDir)</code></th>
<td class="colLast">
<div class="block">Import files from an existing Spark table to an Iceberg table.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,boolean)">importSparkTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                java.lang.String&nbsp;stagingDir,
                boolean&nbsp;checkDuplicateFiles)</code></th>
<td class="colLast">
<div class="block">Import files from an existing Spark table to an Iceberg table.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,int)">importSparkTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                java.lang.String&nbsp;stagingDir,
                int&nbsp;parallelism)</code></th>
<td class="colLast">
<div class="block">Import files from an existing Spark table to an Iceberg table.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,java.util.concurrent.ExecutorService)">importSparkTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                java.lang.String&nbsp;stagingDir,
                java.util.concurrent.ExecutorService&nbsp;service)</code></th>
<td class="colLast">
<div class="block">Import files from an existing Spark table to an Iceberg table.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,java.util.Map,boolean)">importSparkTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                java.lang.String&nbsp;stagingDir,
                java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter,
                boolean&nbsp;checkDuplicateFiles)</code></th>
<td class="colLast">
<div class="block">Import files from an existing Spark table to an Iceberg table.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,java.util.Map,boolean,int)">importSparkTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                java.lang.String&nbsp;stagingDir,
                java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter,
                boolean&nbsp;checkDuplicateFiles,
                int&nbsp;parallelism)</code></th>
<td class="colLast">
<div class="block">Import files from an existing Spark table to an Iceberg table.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>static void</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,java.util.Map,boolean,java.util.concurrent.ExecutorService)">importSparkTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                java.lang.String&nbsp;stagingDir,
                java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter,
                boolean&nbsp;checkDuplicateFiles,
                java.util.concurrent.ExecutorService&nbsp;service)</code></th>
<td class="colLast">
<div class="block">Import files from an existing Spark table to an Iceberg table.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code>static org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#loadMetadataTable(org.apache.spark.sql.SparkSession,org.apache.iceberg.Table,org.apache.iceberg.MetadataTableType)">loadMetadataTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                 <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;table,
                 <a href="../MetadataTableType.html" title="enum in org.apache.iceberg">MetadataTableType</a>&nbsp;type)</code></th>
<td class="colLast">&nbsp;</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>static org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#loadMetadataTable(org.apache.spark.sql.SparkSession,org.apache.iceberg.Table,org.apache.iceberg.MetadataTableType,java.util.Map)">loadMetadataTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                 <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;table,
                 <a href="../MetadataTableType.html" title="enum in org.apache.iceberg">MetadataTableType</a>&nbsp;type,
                 java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;extraOptions)</code></th>
<td class="colLast">&nbsp;</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>static org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#loadTable(org.apache.spark.sql.SparkSession,org.apache.iceberg.Table,long)">loadTable</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
         <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;table,
         long&nbsp;snapshotId)</code></th>
<td class="colLast">&nbsp;</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code>static org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#partitionDF(org.apache.spark.sql.SparkSession,java.lang.String)">partitionDF</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
           java.lang.String&nbsp;table)</code></th>
<td class="colLast">
<div class="block">Returns a DataFrame with a row for each partition in the table.</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>static org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#partitionDFByFilter(org.apache.spark.sql.SparkSession,java.lang.String,java.lang.String)">partitionDFByFilter</a></span>&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                   java.lang.String&nbsp;table,
                   java.lang.String&nbsp;expression)</code></th>
<td class="colLast">
<div class="block">Returns a DataFrame with a row for each partition that matches the specified 'expression'.</div>
</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<th class="colSecond" scope="row"><code><span class="memberNameLink"><a href="#wapEnabled(org.apache.iceberg.Table)">wapEnabled</a></span>&#8203;(<a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;table)</code></th>
<td class="colLast">&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a id="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</section>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<section>
<ul class="blockList">
<li class="blockList"><a id="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a id="partitionDF(org.apache.spark.sql.SparkSession,java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionDF</h4>
<pre class="methodSignature">public static&nbsp;org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;&nbsp;partitionDF&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                                                 java.lang.String&nbsp;table)</pre>
<div class="block">Returns a DataFrame with a row for each partition in the table.

 <p>The DataFrame has 3 columns, partition key (a=1/b=2), partition location, and format (avro
 or parquet).</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>table</code> - a table name and (optional) database</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a DataFrame of the table's partitions</dd>
</dl>
</li>
</ul>
<a id="partitionDFByFilter(org.apache.spark.sql.SparkSession,java.lang.String,java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionDFByFilter</h4>
<pre class="methodSignature">public static&nbsp;org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;&nbsp;partitionDFByFilter&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                                                         java.lang.String&nbsp;table,
                                                                                         java.lang.String&nbsp;expression)</pre>
<div class="block">Returns a DataFrame with a row for each partition that matches the specified 'expression'.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session.</dd>
<dd><code>table</code> - name of the table.</dd>
<dd><code>expression</code> - The expression whose matching partitions are returned.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a DataFrame of the table partitions.</dd>
</dl>
</li>
</ul>
<a id="getPartitions(org.apache.spark.sql.SparkSession,java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPartitions</h4>
<pre class="methodSignature">public static&nbsp;java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;getPartitions&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                                          java.lang.String&nbsp;table)</pre>
<div class="block">Returns all partitions in the table.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>table</code> - a table name and (optional) database</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>all table's partitions</dd>
</dl>
</li>
</ul>
<a id="getPartitions(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPartitions</h4>
<pre class="methodSignature">public static&nbsp;java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;getPartitions&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                                          org.apache.spark.sql.catalyst.TableIdentifier&nbsp;tableIdent,
                                                                          java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter)</pre>
<div class="block">Returns all partitions in the table.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>tableIdent</code> - a table identifier</dd>
<dd><code>partitionFilter</code> - partition filter, or null if no filter</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>all table's partitions</dd>
</dl>
</li>
</ul>
<a id="getPartitionsByFilter(org.apache.spark.sql.SparkSession,java.lang.String,java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPartitionsByFilter</h4>
<pre class="methodSignature">public static&nbsp;java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;getPartitionsByFilter&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                                                  java.lang.String&nbsp;table,
                                                                                  java.lang.String&nbsp;predicate)</pre>
<div class="block">Returns partitions that match the specified 'predicate'.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>table</code> - a table name and (optional) database</dd>
<dd><code>predicate</code> - a predicate on partition columns</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>matching table's partitions</dd>
</dl>
</li>
</ul>
<a id="getPartitionsByFilter(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.spark.sql.catalyst.expressions.Expression)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPartitionsByFilter</h4>
<pre class="methodSignature">public static&nbsp;java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;getPartitionsByFilter&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                                                  org.apache.spark.sql.catalyst.TableIdentifier&nbsp;tableIdent,
                                                                                  org.apache.spark.sql.catalyst.expressions.Expression&nbsp;predicateExpr)</pre>
<div class="block">Returns partitions that match the specified 'predicate'.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>tableIdent</code> - a table identifier</dd>
<dd><code>predicateExpr</code> - a predicate expression on partition columns</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>matching table's partitions</dd>
</dl>
</li>
</ul>
<a id="importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,java.util.Map,boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkTable</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                    org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                                    <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                    java.lang.String&nbsp;stagingDir,
                                    java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter,
                                    boolean&nbsp;checkDuplicateFiles)</pre>
<div class="block">Import files from an existing Spark table to an Iceberg table.

 <p>The import uses the Spark session to get table metadata. It assumes no operation is going on
 the original and target table and thus is not thread-safe.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>sourceTableIdent</code> - an identifier of the source Spark table</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
<dd><code>partitionFilter</code> - only import partitions whose values match those in the map, can be
     partially defined</dd>
<dd><code>checkDuplicateFiles</code> - if true, throw exception if import results in a duplicate data file</dd>
</dl>
</li>
</ul>
<a id="importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkTable</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                    org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                                    <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                    java.lang.String&nbsp;stagingDir,
                                    int&nbsp;parallelism)</pre>
<div class="block">Import files from an existing Spark table to an Iceberg table.

 <p>The import uses the Spark session to get table metadata. It assumes no operation is going on
 the original and target table and thus is not thread-safe.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>sourceTableIdent</code> - an identifier of the source Spark table</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
<dd><code>parallelism</code> - number of threads to use for file reading</dd>
</dl>
</li>
</ul>
<a id="importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,java.util.concurrent.ExecutorService)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkTable</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                    org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                                    <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                    java.lang.String&nbsp;stagingDir,
                                    java.util.concurrent.ExecutorService&nbsp;service)</pre>
<div class="block">Import files from an existing Spark table to an Iceberg table.

 <p>The import uses the Spark session to get table metadata. It assumes no operation is going on
 the original and target table and thus is not thread-safe.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>sourceTableIdent</code> - an identifier of the source Spark table</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
<dd><code>service</code> - executor service to use for file reading. If null, file reading will be
     performed on the current thread. * If non-null, the provided ExecutorService will be
     shutdown within this method after file reading is complete.</dd>
</dl>
</li>
</ul>
<a id="importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,java.util.Map,boolean,int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkTable</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                    org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                                    <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                    java.lang.String&nbsp;stagingDir,
                                    java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter,
                                    boolean&nbsp;checkDuplicateFiles,
                                    int&nbsp;parallelism)</pre>
<div class="block">Import files from an existing Spark table to an Iceberg table.

 <p>The import uses the Spark session to get table metadata. It assumes no operation is going on
 the original and target table and thus is not thread-safe.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>sourceTableIdent</code> - an identifier of the source Spark table</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
<dd><code>partitionFilter</code> - only import partitions whose values match those in the map, can be
     partially defined</dd>
<dd><code>checkDuplicateFiles</code> - if true, throw exception if import results in a duplicate data file</dd>
<dd><code>parallelism</code> - number of threads to use for file reading</dd>
</dl>
</li>
</ul>
<a id="importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,java.util.Map,boolean,java.util.concurrent.ExecutorService)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkTable</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                    org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                                    <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                    java.lang.String&nbsp;stagingDir,
                                    java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter,
                                    boolean&nbsp;checkDuplicateFiles,
                                    java.util.concurrent.ExecutorService&nbsp;service)</pre>
<div class="block">Import files from an existing Spark table to an Iceberg table.

 <p>The import uses the Spark session to get table metadata. It assumes no operation is going on
 the original and target table and thus is not thread-safe.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>sourceTableIdent</code> - an identifier of the source Spark table</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
<dd><code>partitionFilter</code> - only import partitions whose values match those in the map, can be
     partially defined</dd>
<dd><code>checkDuplicateFiles</code> - if true, throw exception if import results in a duplicate data file</dd>
<dd><code>service</code> - executor service to use for file reading. If null, file reading will be
     performed on the current thread. If non-null, the provided ExecutorService will be shutdown
     within this method after file reading is complete.</dd>
</dl>
</li>
</ul>
<a id="importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String,boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkTable</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                    org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                                    <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                    java.lang.String&nbsp;stagingDir,
                                    boolean&nbsp;checkDuplicateFiles)</pre>
<div class="block">Import files from an existing Spark table to an Iceberg table.

 <p>The import uses the Spark session to get table metadata. It assumes no operation is going on
 the original and target table and thus is not thread-safe.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>sourceTableIdent</code> - an identifier of the source Spark table</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
<dd><code>checkDuplicateFiles</code> - if true, throw exception if import results in a duplicate data file</dd>
</dl>
</li>
</ul>
<a id="importSparkTable(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.TableIdentifier,org.apache.iceberg.Table,java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkTable</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                    org.apache.spark.sql.catalyst.TableIdentifier&nbsp;sourceTableIdent,
                                    <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                    java.lang.String&nbsp;stagingDir)</pre>
<div class="block">Import files from an existing Spark table to an Iceberg table.

 <p>The import uses the Spark session to get table metadata. It assumes no operation is going on
 the original and target table and thus is not thread-safe.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>sourceTableIdent</code> - an identifier of the source Spark table</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
</dl>
</li>
</ul>
<a id="importSparkPartitions(org.apache.spark.sql.SparkSession,java.util.List,org.apache.iceberg.Table,org.apache.iceberg.PartitionSpec,java.lang.String,boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkPartitions</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkPartitions&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                         java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                                         <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                         <a href="../PartitionSpec.html" title="class in org.apache.iceberg">PartitionSpec</a>&nbsp;spec,
                                         java.lang.String&nbsp;stagingDir,
                                         boolean&nbsp;checkDuplicateFiles)</pre>
<div class="block">Import files from given partitions to an Iceberg table.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>partitions</code> - partitions to import</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>spec</code> - a partition spec</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
<dd><code>checkDuplicateFiles</code> - if true, throw exception if import results in a duplicate data file</dd>
</dl>
</li>
</ul>
<a id="importSparkPartitions(org.apache.spark.sql.SparkSession,java.util.List,org.apache.iceberg.Table,org.apache.iceberg.PartitionSpec,java.lang.String,boolean,int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkPartitions</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkPartitions&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                         java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                                         <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                         <a href="../PartitionSpec.html" title="class in org.apache.iceberg">PartitionSpec</a>&nbsp;spec,
                                         java.lang.String&nbsp;stagingDir,
                                         boolean&nbsp;checkDuplicateFiles,
                                         int&nbsp;parallelism)</pre>
<div class="block">Import files from given partitions to an Iceberg table.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>partitions</code> - partitions to import</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>spec</code> - a partition spec</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
<dd><code>checkDuplicateFiles</code> - if true, throw exception if import results in a duplicate data file</dd>
<dd><code>parallelism</code> - number of threads to use for file reading</dd>
</dl>
</li>
</ul>
<a id="importSparkPartitions(org.apache.spark.sql.SparkSession,java.util.List,org.apache.iceberg.Table,org.apache.iceberg.PartitionSpec,java.lang.String,boolean,java.util.concurrent.ExecutorService)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkPartitions</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkPartitions&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                         java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                                         <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                         <a href="../PartitionSpec.html" title="class in org.apache.iceberg">PartitionSpec</a>&nbsp;spec,
                                         java.lang.String&nbsp;stagingDir,
                                         boolean&nbsp;checkDuplicateFiles,
                                         java.util.concurrent.ExecutorService&nbsp;service)</pre>
<div class="block">Import files from given partitions to an Iceberg table.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>partitions</code> - partitions to import</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>spec</code> - a partition spec</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
<dd><code>checkDuplicateFiles</code> - if true, throw exception if import results in a duplicate data file</dd>
<dd><code>service</code> - executor service to use for file reading. If null, file reading will be
     performed on the current thread. If non-null, the provided ExecutorService will be shutdown
     within this method after file reading is complete.</dd>
</dl>
</li>
</ul>
<a id="importSparkPartitions(org.apache.spark.sql.SparkSession,java.util.List,org.apache.iceberg.Table,org.apache.iceberg.PartitionSpec,java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>importSparkPartitions</h4>
<pre class="methodSignature">public static&nbsp;void&nbsp;importSparkPartitions&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                         java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                                         <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;targetTable,
                                         <a href="../PartitionSpec.html" title="class in org.apache.iceberg">PartitionSpec</a>&nbsp;spec,
                                         java.lang.String&nbsp;stagingDir)</pre>
<div class="block">Import files from given partitions to an Iceberg table.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark session</dd>
<dd><code>partitions</code> - partitions to import</dd>
<dd><code>targetTable</code> - an Iceberg table where to import the data</dd>
<dd><code>spec</code> - a partition spec</dd>
<dd><code>stagingDir</code> - a staging directory to store temporary manifest files</dd>
</dl>
</li>
</ul>
<a id="filterPartitions(java.util.List,java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>filterPartitions</h4>
<pre class="methodSignature">public static&nbsp;java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;filterPartitions&#8203;(java.util.List&lt;<a href="SparkTableUtil.SparkPartition.html" title="class in org.apache.iceberg.spark">SparkTableUtil.SparkPartition</a>&gt;&nbsp;partitions,
                                                                             java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;partitionFilter)</pre>
</li>
</ul>
<a id="loadTable(org.apache.spark.sql.SparkSession,org.apache.iceberg.Table,long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>loadTable</h4>
<pre class="methodSignature">public static&nbsp;org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;&nbsp;loadTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                                               <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;table,
                                                                               long&nbsp;snapshotId)</pre>
</li>
</ul>
<a id="loadMetadataTable(org.apache.spark.sql.SparkSession,org.apache.iceberg.Table,org.apache.iceberg.MetadataTableType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>loadMetadataTable</h4>
<pre class="methodSignature">public static&nbsp;org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;&nbsp;loadMetadataTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                                                       <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;table,
                                                                                       <a href="../MetadataTableType.html" title="enum in org.apache.iceberg">MetadataTableType</a>&nbsp;type)</pre>
</li>
</ul>
<a id="loadMetadataTable(org.apache.spark.sql.SparkSession,org.apache.iceberg.Table,org.apache.iceberg.MetadataTableType,java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>loadMetadataTable</h4>
<pre class="methodSignature">public static&nbsp;org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;&nbsp;loadMetadataTable&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                                                       <a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;table,
                                                                                       <a href="../MetadataTableType.html" title="enum in org.apache.iceberg">MetadataTableType</a>&nbsp;type,
                                                                                       java.util.Map&lt;java.lang.String,&#8203;java.lang.String&gt;&nbsp;extraOptions)</pre>
</li>
</ul>
<a id="determineWriteBranch(org.apache.spark.sql.SparkSession,java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>determineWriteBranch</h4>
<pre class="methodSignature">public static&nbsp;java.lang.String&nbsp;determineWriteBranch&#8203;(org.apache.spark.sql.SparkSession&nbsp;spark,
                                                    java.lang.String&nbsp;branch)</pre>
<div class="block">Determine the write branch.

 <p>Validate wap config and determine the write branch.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spark</code> - a Spark Session</dd>
<dd><code>branch</code> - write branch if there is no WAP branch configured</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>branch for write operation</dd>
</dl>
</li>
</ul>
<a id="wapEnabled(org.apache.iceberg.Table)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>wapEnabled</h4>
<pre class="methodSignature">public static&nbsp;boolean&nbsp;wapEnabled&#8203;(<a href="../Table.html" title="interface in org.apache.iceberg">Table</a>&nbsp;table)</pre>
</li>
</ul>
</li>
</ul>
</section>
</li>
</ul>
</div>
</div>
</main>
<!-- ========= END OF CLASS DATA ========= -->
<footer role="contentinfo">
<nav role="navigation">
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a id="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a id="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a id="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</nav>
</footer>
</body>
</html>
