/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

configurations {
    integrationImplementation.extendsFrom testImplementation
    integrationRuntime.extendsFrom testRuntimeOnly
}

String scalaVersion = System.getProperty("scalaVersion") != null ? System.getProperty("scalaVersion") : System.getProperty("defaultScalaVersion")
String sparkVersionsString = System.getProperty("sparkVersions") != null ? System.getProperty("sparkVersions") : System.getProperty("defaultSparkVersions")
List<String> sparkVersions = sparkVersionsString != null && !sparkVersionsString.isEmpty() ? sparkVersionsString.split(",") : []

dependencies {
    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')
    api project(':iceberg-api')
    implementation project(':iceberg-common')
    implementation project(':iceberg-core')
    implementation project(':iceberg-parquet')
    implementation platform(libs.jackson.bom)
    implementation "com.fasterxml.jackson.core:jackson-databind"
    annotationProcessor libs.immutables.value
    compileOnly libs.immutables.value

    compileOnly "io.delta:delta-standalone_${scalaVersion}:${libs.versions.delta.standalone.get()}"

    compileOnly(libs.hadoop2.common) {
        exclude group: 'org.apache.avro', module: 'avro'
        exclude group: 'org.slf4j', module: 'slf4j-log4j12'
        exclude group: 'javax.servlet', module: 'servlet-api'
        exclude group: 'com.google.code.gson', module: 'gson'
    }

    // The newest version of delta-core uses Spark 3.5.*. Since its only for test, we do
    // not need to include older version of delta-core
    if (sparkVersions.contains("3.5")) {
        integrationImplementation "io.delta:delta-spark_${scalaVersion}:${libs.versions.delta.spark.get()}"
        integrationImplementation project(path: ":iceberg-spark:iceberg-spark-3.5_${scalaVersion}")
        integrationImplementation(libs.hadoop2.minicluster) {
            exclude group: 'org.apache.avro', module: 'avro'
            // to make sure netty libs only come from project(':iceberg-arrow')
            exclude group: 'io.netty', module: 'netty-buffer'
            exclude group: 'io.netty', module: 'netty-common'
        }
        integrationImplementation project(path: ':iceberg-hive-metastore')
        integrationImplementation project(path: ':iceberg-hive-metastore', configuration: 'testArtifacts')
        integrationImplementation("org.apache.spark:spark-hive_${scalaVersion}:${libs.versions.spark.hive35.get()}") {
            exclude group: 'org.apache.avro', module: 'avro'
            exclude group: 'org.apache.arrow'
            exclude group: 'org.apache.parquet'
            // to make sure netty libs only come from project(':iceberg-arrow')
            exclude group: 'io.netty', module: 'netty-buffer'
            exclude group: 'io.netty', module: 'netty-common'
            exclude group: 'org.roaringbitmap'
        }
    }
}

// use integration test since we can take advantages of spark 3.3 to read datafiles of delta lake table
// and create some tests involving sql query.
test {
    useJUnitPlatform()
}
